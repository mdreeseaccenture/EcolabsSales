{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read two of the reqiured csv files\n",
    "\n",
    "company_ds = dd.read_csv('free_company_dataset.csv', on_bad_lines='skip')\n",
    "recall_ds = dd.read_csv('recalls-market-withdrawals-safety-alerts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_states = [\n",
    "    #usa\n",
    "    'alabama',\n",
    "    'alaska',\n",
    "    'arizona',\n",
    "    'arkansas',\n",
    "    'california',\n",
    "    'colorado',\n",
    "    'connecticut',\n",
    "    'delaware',\n",
    "    'florida',\n",
    "    'georgia',\n",
    "    'hawaii',\n",
    "    'idaho',\n",
    "    'illinois',\n",
    "    'indiana',\n",
    "    'iowa',\n",
    "    'kansas',\n",
    "    'kentucky',\n",
    "    'louisiana',\n",
    "    'maine',\n",
    "    'maryland',\n",
    "    'massachusetts',\n",
    "    'michigan',\n",
    "    'minnesota',\n",
    "    'mississippi',\n",
    "    'missouri',\n",
    "    'montana',\n",
    "    'nebraska',\n",
    "    'nevada',\n",
    "    'new hampshire',\n",
    "    'new jersey',\n",
    "    'new mexico',\n",
    "    'new york',\n",
    "    'north carolina',\n",
    "    'north dakota',\n",
    "    'ohio',\n",
    "    'oklahoma',\n",
    "    'oregon',\n",
    "    'pennsylvania',\n",
    "    'rhode island',\n",
    "    'south carolina',\n",
    "    'south dakota',\n",
    "    'tennessee',\n",
    "    'texas',\n",
    "    'utah',\n",
    "    'vermont',\n",
    "    'virginia',\n",
    "    'washington',\n",
    "    'west virginia',\n",
    "    'wisconsin',\n",
    "    'wyoming',\n",
    "    #canada\n",
    "    'alberta',\n",
    "    'british columbia',\n",
    "    'manitoba',\n",
    "    'new brunswick',\n",
    "    'newfoundland and labrador',\n",
    "    'nova scotia',\n",
    "    'ontario',\n",
    "    'prince edward island',\n",
    "    'quebec',\n",
    "    'saskatchewan',\n",
    "    'northwest territories',\n",
    "    'nunavut',\n",
    "    'yukon',\n",
    "    #mexico\n",
    "    'aguascalientes',\n",
    "    'baja california',\n",
    "    'baja california sur',\n",
    "    'campeche',\n",
    "    'chiapas',\n",
    "    'chihuahua',\n",
    "    'coahuila',\n",
    "    'colima',\n",
    "    'durango',\n",
    "    'guanajuato',\n",
    "    'guerrero',\n",
    "    'hidalgo',\n",
    "    'jalisco',\n",
    "    'mexico state',\n",
    "    'michoacan',\n",
    "    'morelos',\n",
    "    'nayarit',\n",
    "    'nuevo leon',\n",
    "    'oaxaca',\n",
    "    'puebla',\n",
    "    'queretaro',\n",
    "    'quintana roo',\n",
    "    'san luis potosi',\n",
    "    'sinaloa',\n",
    "    'sonora',\n",
    "    'tabasco',\n",
    "    'tamaulipas',\n",
    "    'tlaxcala',\n",
    "    'veracruz',\n",
    "    'yucatan',\n",
    "    'zacatecas'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\core.py:4419: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('region', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "#removing accents from the region column for better matching\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "company_ds['region_no_accents'] = company_ds['region'].apply(lambda x: unidecode(str(x)).lower().strip())\n",
    "na_regions_processed = [unidecode(region).lower().strip() for region in na_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering NA records from the company dataset\n",
    "\n",
    "na_records = company_ds[company_ds['region_no_accents'].isin(na_regions_processed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\accessor.py:96: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  out = getattr(getattr(obj, accessor, obj), attr)(*args, **kwargs)\n",
      "c:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\accessor.py:96: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  out = getattr(getattr(obj, accessor, obj), attr)(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the company name columns in all three datasets due to descripancies in their naming conventions\n",
    "\n",
    "na_records['id_processed'] = na_records['id'].str.lower().str.replace('[^a-z0-9]','').str.strip()\n",
    "del company_ds\n",
    "\n",
    "recall_ds['Brand-Names_processed'] = recall_ds['Brand-Names'].str.replace('[^a-z0-9]','').str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing 1st outer join\n",
    "\n",
    "company_recall_merged = na_records.merge(recall_ds, left_on='id_processed', right_on='Brand-Names_processed', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\accessor.py:96: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  out = getattr(getattr(obj, accessor, obj), attr)(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#deleting old DFs which are not required & reading the 3rd csv file\n",
    "\n",
    "del na_records\n",
    "del recall_ds\n",
    "violations_ds = dd.read_csv('Data_Download_ECHO_10_17_2023_652eac22dbb06.csv',dtype={'RegistryID': 'object',\n",
    "       'SupOver80CountUsDisp': 'object'})\n",
    "\n",
    "violations_ds['FacName_processed'] = violations_ds['FacName'].str.replace('[^a-z0-9]','').str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing final merge operation\n",
    "\n",
    "all_merged = company_recall_merged.merge(violations_ds, left_on='id_processed', right_on='FacName_processed', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=all_merged.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.7 GiB for an array with shape (18, 132165827) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Downloads\\Untitled Folder\\temp.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khushaal.a.chaudhary/Downloads/Untitled%20Folder/temp.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_merged\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mmerged_output.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, single_file\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\core.py:1897\u001b[0m, in \u001b[0;36m_Frame.to_csv\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m   1894\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   1895\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataframe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m to_csv\n\u001b[1;32m-> 1897\u001b[0m \u001b[39mreturn\u001b[39;00m to_csv(\u001b[39mself\u001b[39m, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:997\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    993\u001b[0m         compute_kwargs[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m    995\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(dask\u001b[39m.\u001b[39mcompute(\u001b[39m*\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompute_kwargs))\n\u001b[0;32m    998\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    999\u001b[0m     \u001b[39mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\dask\\dataframe\\multi.py:289\u001b[0m, in \u001b[0;36mmerge_chunk\u001b[1;34m(lhs, result_meta, *args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m                 rhs \u001b[39m=\u001b[39m rhs\u001b[39m.\u001b[39massign(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{col: right\u001b[39m.\u001b[39mastype(dtype)})\n\u001b[1;32m--> 289\u001b[0m out \u001b[39m=\u001b[39m lhs\u001b[39m.\u001b[39mmerge(rhs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m \u001b[39m# Workaround for pandas bug where if the left frame of a merge operation is\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m# empty, the resulting dataframe can have columns in the wrong order.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m# https://github.com/pandas-dev/pandas/issues/9937\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lhs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\khushaal.a.chaudhary\\Anaconda3\\envs\\geo_gensim_env\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:149\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    147\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    151\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    152\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.7 GiB for an array with shape (18, 132165827) and data type object"
     ]
    }
   ],
   "source": [
    "#saving the results in a csv file\n",
    "#Note that this is the point at which we get a memory error\n",
    "\n",
    "all_merged.to_csv('merged_output.csv',index=False, single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_gensim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
